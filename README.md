<p align="center">
  <img src="https://img.shields.io/badge/python-3.10%2B-blue?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/LLM-GPT--4o-412991?style=for-the-badge&logo=openai&logoColor=white" />
  <img src="https://img.shields.io/badge/protocol-MCP-orange?style=for-the-badge" />
</p>

<h1 align="center">ğŸ¤– Agent MCP</h1>

<p align="center">
  <strong>A lightweight, tool-augmented AI agent powered by GPT-4o and the Model Context Protocol.</strong>
</p>

<p align="center">
  Think â†’ Plan â†’ Act â†’ Observe â†’ Answer<br/>
  A reasoning loop that connects an LLM to the real world through pluggable tools â€” both local and remote.
</p>

---

## âœ¨ What is this?

**Agent MCP** is a minimal yet powerful autonomous agent that:

1. **Receives** a natural language query from the user
2. **Plans** a sequence of tool calls using GPT-4o (with structured JSON reasoning)
3. **Executes** tools one by one â€” calculators, web search, file I/O, chart generation, and more
4. **Observes** each tool's output and feeds it back into the reasoning loop
5. **Answers** with a final, human-friendly response

It supports both **local tools** (bundled in the project) and **remote tools** discovered dynamically via a [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) server â€” making it easily extensible without touching the agent core.

---

## ğŸ—ï¸ Architecture

```
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚     User Query      â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚    Agent Runner     â”‚
                          â”‚  (think â†’ act loop) â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â–¼              â–¼               â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Local Tools â”‚ â”‚  LLM API  â”‚  â”‚ MCP Server  â”‚
              â”‚ (calc, ioâ€¦) â”‚ â”‚ (GPT-4o)  â”‚  â”‚  (remote)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                                           â”‚  Remote Tools   â”‚
                                           â”‚ (prometheus,    â”‚
                                           â”‚  weather, etc.) â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§° Built-in Tools

| Tool | Description |
|------|-------------|
| `echo` | Echoes input back â€” useful for testing |
| `calc` | Evaluates mathematical expressions |
| `search` | Performs web searches |
| `file` | Reads and writes local files |
| `current_time` | Returns the current date and time |
| `graph` | Generates charts (bar, pie, line) as PNG images |
| `mcp_proxy` | Bridges any remote MCP tool into the local agent |

Remote tools (Prometheus queries, weather data, etc.) are auto-discovered from the MCP server at startup.

---

## ğŸ“‚ Project Structure

```
agent-mcp/
â”œâ”€â”€ agent.py                # Core agent loop (think â†’ act â†’ observe)
â”œâ”€â”€ cli.py                  # Interactive CLI interface
â”œâ”€â”€ llm.py                  # Minimal OpenAI GPT-4o wrapper (zero dependencies)
â”œâ”€â”€ mcp/
â”‚   â”œâ”€â”€ server.py           # FastMCP server (exposes remote tools)
â”‚   â””â”€â”€ tools/              # MCP tool definitions (prometheus, weather)
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py         # Tool registry & discovery
â”‚   â”œâ”€â”€ calc_tool.py        # Math expression evaluator
â”‚   â”œâ”€â”€ current_time_tool.py
â”‚   â”œâ”€â”€ echo_tool.py
â”‚   â”œâ”€â”€ file_tool.py        # File read/write operations
â”‚   â”œâ”€â”€ graph_tool.py       # Chart generation (matplotlib)
â”‚   â”œâ”€â”€ mcp_proxy_tool.py   # Remote MCP tool proxy
â”‚   â””â”€â”€ search_tool.py      # Web search integration
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_agent_basic.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ TODO.md
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.10+** (3.13 recommended)
- An **OpenAI API key** (`OPENAI_API_KEY`)

### Installation

```bash
# Clone the repository
git clone https://github.com/Samanosukeh/agent-mcp.git
cd agent-mcp

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate   # Linux/macOS
venv\Scripts\activate      # Windows

# Install dependencies
pip install -r requirements.txt
```

### Environment Setup

Create a `.env` file in the project root:

```env
OPENAI_API_KEY=your-openai-api-key
MCP_API_KEY=changeme
MCP_URL=http://127.0.0.1:8000/mcp
```

> `MCP_URL` is optional â€” if omitted, the agent runs with local tools only.

---

## â–¶ï¸ Usage

### Start the MCP Server (optional)

```bash
python -m mcp.server
# or directly with uvicorn:
uvicorn mcp.server:app --host 127.0.0.1 --port 8000
```

The server exposes:
- `/mcp` â€” MCP protocol endpoint
- `/mcp/overview` â€” lists all registered remote tools

### Run the Agent

```bash
# Interactive CLI
python cli.py

# With a custom prompt file
python cli.py -p my_prompt.txt
```

### Example Queries

```
Query> What time is it?
Query> Calculate 2^10 + 37 * 4
Query> Generate a pie chart with data [10, 30, 25, 35] and labels ["A", "B", "C", "D"]
Query> Run the Prometheus query 'avg_over_time(cpu_usage[1h])'
Query> What's the weather in SÃ£o Paulo?
```

---

## ğŸ§ª Running Tests

```bash
python -m pytest tests/
```

---

## ğŸ¤ Contributing

To ensure code quality, set up pre-commit hooks:

```bash
pip install pre-commit
pre-commit install
```

This runs linting checks (flake8) automatically on every commit.

---

## ğŸ“Œ Roadmap

- [ ] ChromaDB vector store for long-term memory
- [ ] Conversation persistence via `conversation_id`
- [ ] Web frontend for browser-based interaction
- [ ] Customizable agent strategies (decision modes, tool prioritization)
- [ ] Colored, human-friendly log output

---

<p align="center">
  Built with curiosity and coffee â˜•
</p>